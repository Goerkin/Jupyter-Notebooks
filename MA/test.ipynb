{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fbprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstatsmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtsa\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marima\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m ARIMA\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfbprophet\u001b[39;00m \u001b[39mimport\u001b[39;00m Prophet\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m LSTM, Dense\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fbprophet'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from fbprophet import Prophet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"/workspace/Jupyter-Notebooks/MA/PRSA_Data_Guanyuan_20130301-20170228.csv\")\n",
    "\n",
    "# Artificially degrade the data by adding noise\n",
    "noise = np.random.normal(0, 0.5, len(data))\n",
    "data[\"PM2.5\"] = data[\"PM2.5\"] + noise\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[:train_size], data[train_size:]\n",
    "\n",
    "# Define a function to evaluate the root mean squared error (RMSE) of a model\n",
    "def evaluate_model(y, yhat):\n",
    "    return np.sqrt(mean_squared_error(y, yhat))\n",
    "\n",
    "# Time series modeling with ARIMA\n",
    "model = ARIMA(train[\"PM2.5\"], order=(1, 1, 1))\n",
    "model_fit = model.fit()\n",
    "yhat_arima = model_fit.predict(len(train), len(data)-1, typ=\"levels\")\n",
    "rmse_arima = evaluate_model(test[\"PM2.5\"], yhat_arima)\n",
    "\n",
    "# Time series modeling with Prophet\n",
    "model = Prophet()\n",
    "model.fit(train[[\"ds\", \"PM2.5\"]].rename(columns={\"ds\": \"ds\", \"PM2.5\": \"y\"}))\n",
    "future = model.make_future_dataframe(periods=len(test), freq=\"H\")\n",
    "yhat_prophet = model.predict(future)[\"yhat\"].tail(len(test))\n",
    "rmse_prophet = evaluate_model(test[\"PM2.5\"], yhat_prophet)\n",
    "\n",
    "# Time series modeling with LSTM\n",
    "window_size = 24\n",
    "train_X, train_y = [], []\n",
    "for i in range(window_size, len(train)):\n",
    "    train_X.append(train[\"PM2.5\"][i-window_size:i])\n",
    "    train_y.append(train[\"PM2.5\"][i])\n",
    "train_X, train_y = np.array(train_X), np.array(train_y)\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(window_size, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(train_X, train_y, epochs=50, batch_size=72, verbose=0)\n",
    "test_X = []\n",
    "for i in range(window_size, len(test)):\n",
    "    test_X.append(test[\"PM2.5\"][i-window_size:i])\n",
    "test_X = np.array(test_X)\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[1], 1))\n",
    "yhat_lstm = model.predict(test_X, verbose=0)\n",
    "yhat_lstm = np.squeeze(yhat_lstm)\n",
    "rmse_lstm = evaluate_model(test[\"PM2.5\"], yhat_lstm)\n",
    "\n",
    "# Print the RMSE of each model\n",
    "print(\"ARIMA RMSE: %.3f\" % rmse_arima)\n",
    "print(\"Prophet RMSE: %.3f\" % rmse_prophet)\n",
    "print(\"LSTM RMSE: %.3f\" % rmse_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep fbprophet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
